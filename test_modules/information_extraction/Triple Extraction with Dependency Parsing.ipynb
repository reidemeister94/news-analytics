{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information extraction using spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract triples (subject, predicate, object) from text via Subtree Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import string \n",
    "import nltk \n",
    "import spacy \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import math \n",
    "from tqdm import tqdm \n",
    "from spacy.matcher import Matcher \n",
    "from spacy.tokens import Span\n",
    "from spacy import displacy\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Tableau was recently acquired by Salesforce.\" \n",
    "\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style = 'dep', jupyter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in doc: \n",
    "    print(tok.text,\"-->\",tok.dep_,\"-->\",tok.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtree_matcher(doc):\n",
    "    subjpass = 0\n",
    "\n",
    "    for i,tok in enumerate(doc):\n",
    "        # find dependency tag that contains the text \"subjpass\"    \n",
    "        if tok.dep_.find(\"subjpass\") == True:\n",
    "            subjpass = 1\n",
    "\n",
    "    subj = ''\n",
    "    pred = ''\n",
    "    obj = ''\n",
    "\n",
    "    # if subjpass == 1 then sentence is passive\n",
    "    if subjpass == 1:\n",
    "        for i,tok in enumerate(doc):\n",
    "            if tok.dep_.find(\"subjpass\") == True:\n",
    "                obj = tok.text\n",
    "            \n",
    "            \n",
    "            \n",
    "            if tok.dep_.endswith(\"obj\") == True:\n",
    "                subj = tok.text\n",
    "\n",
    "    # if subjpass == 0 then sentence is not passive\n",
    "    else:\n",
    "        for i,tok in enumerate(doc):\n",
    "            if tok.dep_.endswith(\"subj\") == True:\n",
    "                subj = tok.text\n",
    "\n",
    "            if tok.dep_.endswith(\"obj\") == True:\n",
    "                obj = tok.text\n",
    "\n",
    "    return subj, obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtree_matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Careem, a ride-hailing major in the middle east, was acquired by Uber.\"\n",
    "\n",
    "doc2 = nlp(text2)\n",
    "subtree_matcher(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"Salesforce recently acquired Tableau.\"\n",
    "\n",
    "doc3 = nlp(text3)\n",
    "subtree_matcher(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "corpus = \"Neuerkirch and Külz abandoned their old fossil fuel heating system for a 100% renewable heating system – a biomass plant supplies 75% of the energy and a solar thermal plant provides for the rest. Only a few homes are not connected to the central system.\"\n",
    "sentences = sent_tokenize(corpus)\n",
    "for sentence in sentences:\n",
    "    print(subtree_matcher(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "text = nlp(\"Neuerkirch and Külz abandoned their old fossil fuel heating system for a 100% renewable heating system – a biomass plant supplies 75% of the energy and a solar thermal plant provides for the rest. Only a few homes are not connected to the central system.\")\n",
    "text_ext = textacy.extract.subject_verb_object_triples(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Neuerkirch, abandoned, heating system)\n",
      "(Külz, abandoned, heating system)\n",
      "(biomass plant, supplies, %)\n"
     ]
    }
   ],
   "source": [
    "for item in text_ext:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = nlp(\"Only a few homes are not connected to the central system.\")\n",
    "text_ext2 = textacy.extract.subject_verb_object_triples(text2)\n",
    "\n",
    "for item in text_ext2:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
