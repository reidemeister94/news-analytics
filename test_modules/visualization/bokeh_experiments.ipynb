{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_file, show\n",
    "from datetime import datetime\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection to local mongo\n",
    "mongourl = \"mongodb://admin:adminpassword@localhost:27017\"\n",
    "client = MongoClient(mongourl)\n",
    "\n",
    "# Retrieve Feb. 2020 only\n",
    "start_year = 2020\n",
    "start_month = 2\n",
    "end_year = 2020\n",
    "end_month = 3\n",
    "start = datetime(start_year, start_month, 1, 0, 0)\n",
    "end = datetime(end_year, end_month, 1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_news_extraction(self, lang, query, limit=10):\n",
    "    if lang != \"it\":\n",
    "        name_coll = \"article_\" + lang\n",
    "    else:\n",
    "        name_coll = \"article\"\n",
    "    collection = client[\"news\"][name_coll]\n",
    "    not_processed_docs = collection.aggregate(query).limit(limit)\n",
    "    return collection, not_processed_docs\n",
    "\n",
    "def build_query(self):\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$and\": [\n",
    "                {\"discoverDate\": {\"$gte\": start, \"$lt\": end}},\n",
    "                {\"topicExtraction\": {\"$exists\": True}},\n",
    "            ]\n",
    "        },\n",
    "        { \n",
    "            \"$addFields\" : { \n",
    "                \"topic\" : { \n",
    "                    \"$arrayElemAt\" : [\n",
    "                        \"$topicExtraction\", \n",
    "                        { \n",
    "                            \"$indexOfArray\" : [\n",
    "                                \"$topicExtraction.topic_prob\", { \"$max\" : \"$topicExtraction.topic_prob\"}\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = \"en\"\n",
    "n_dims = 50\n",
    "bert_embedding_size = 768\n",
    "num_topics = 20\n",
    "\n",
    "print(\"Looking from {} to {}\".format(self.START.strftime(\"%Y/%m\"), self.END.strftime(\"%Y/%m\")))\n",
    "query = self.build_query()\n",
    "_, not_processed_docs = self.db_news_extraction(lang, query, limit=10)\n",
    "\n",
    "embeddings = []\n",
    "topic_numbers = []\n",
    "for doc in not_processed_docs:\n",
    "    print(\"=\"*30)\n",
    "    print(\"Doc {} titled '{}' contains topic n.{} w/ {} probability\".format(\n",
    "        doc[\"id\"], doc[\"title\"], doc[\"topic\"][\"topic_number\"], doc[\"topic_prob\"]\n",
    "    ))\n",
    "    print(\"--> Relevant word are: {}\".format(doc[\"topic\"][\"topic_tokens\"]))\n",
    "\n",
    "    #embeddings = np.append(embeddings, np.array(doc[\"bertEncoding\"]))\n",
    "    # topic_probs = [el[\"topic_prob\"] for el in doc[\"testTopicExtraction\"]]\n",
    "    #topic_probs = [el[\"topic_prob\"] for el in doc[\"topicExtraction\"]]\n",
    "    #topic_max_prob = np.argmax(topic_probs)\n",
    "    # doc_topic_max_prob = doc[\"testTopicExtraction\"][topic_max_prob]\n",
    "    #doc_topic_max_prob = doc[\"topicExtraction\"][topic_max_prob]\n",
    "    #topic_numbers = np.append(topic_numbers, doc_topic_max_prob[\"topic_number\"])\n",
    "if len(topic_numbers) > 0:\n",
    "    print(\"Found some articles\")\n",
    "    topic_numbers = np.asarray(topic_numbers)\n",
    "    topic_numbers = topic_numbers.astype(\"int32\")\n",
    "    embeddings = np.reshape(embeddings, (-1, bert_embedding_size))\n",
    "    print(embeddings.shape)\n",
    "    print(\"Reducing dimensions\")\n",
    "    results = self.reduce_dim(embeddings, n_dims)\n",
    "    print(results.shape)\n",
    "    self.plot_dim_reduction(\n",
    "        results, num_topics, topic_numbers, self.create_file_path()\n",
    "    )\n",
    "self.update_dates()\n",
    "\n",
    "not_processed_docs.close()"
   ]
  }
 ]
}