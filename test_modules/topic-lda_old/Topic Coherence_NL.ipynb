{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import datetime\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.utils import ClippedCorpus\n",
    "from gensim.models import Phrases, CoherenceModel\n",
    "from gensim import corpora, models\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection to mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongourl = \"mongodb://admin:adminpassword@localhost:27017\"\n",
    "mongo_client = MongoClient(mongourl)\n",
    "\n",
    "collection = mongo_client[\"news\"][\"article_nl\"]\n",
    "not_processed_docs = collection.find(\n",
    "    {\n",
    "        \"$or\": [\n",
    "            {\"processedEncoding\": False},\n",
    "            {\"processedEncoding\": {\"$exists\": False}},\n",
    "        ]\n",
    "    }\n",
    ").limit(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"nl_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'for word in nlp.Defaults.stop_words:\\n        if nlp.vocab[word].is_stop:\\n            print(word)'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "'''for word in nlp.Defaults.stop_words:\n",
    "        if nlp.vocab[word].is_stop:\n",
    "            print(word)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_stop_words():\n",
    "    for word in nlp.Defaults.stop_words:\n",
    "        nlp.vocab[word].is_stop = True\n",
    "    return\n",
    "\n",
    "def add_custom_stop_words(custom_stop_words):\n",
    "    for cw in custom_stop_words:\n",
    "        nlp.vocab[cw].is_stop = True\n",
    "    return\n",
    "\n",
    "def sentence_tokenize(data):\n",
    "    return [sent for sent in data.sents]\n",
    "\n",
    "def lemmatize_tokens(data):\n",
    "    lemmas = []\n",
    "    for sent in data:\n",
    "        sent_tokens = []\n",
    "        for token in sent:\n",
    "            candidate = token.lemma_.replace(\"’\", \"\")\n",
    "            if (not nlp.vocab[candidate].is_stop and not token.is_punct and\n",
    "                len(candidate) > 1 and not candidate.isspace()):\n",
    "                sent_tokens.append(candidate)\n",
    "        lemmas.append(sent_tokens)\n",
    "        sent_tokens = []\n",
    "    return lemmas\n",
    "\n",
    "def flatten_list(data):\n",
    "    return list(chain.from_iterable(data))\n",
    "\n",
    "fix_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(raw_data):\n",
    "    doc = nlp(raw_data)\n",
    "    # Retrieve sentences\n",
    "    sentences = sentence_tokenize(doc)\n",
    "    # print(len(sentences))\n",
    "    # Lemmatize + remove stop words\n",
    "    lemmas = lemmatize_tokens(sentences)\n",
    "    # print(len(lemmas))\n",
    "    # Flatten results into a single list\n",
    "    parsed_text = flatten_list(lemmas)\n",
    "\n",
    "    return parsed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list with parsed documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for doc in not_processed_docs:\n",
    "    parsed_doc = parse_text(doc[\"text\"])\n",
    "    documents.append(parsed_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_collocations(tokens):\n",
    "    bigrams = Phrases(tokens)\n",
    "    trigrams = Phrases(bigrams[tokens], min_count=1)\n",
    "    return list(trigrams[bigrams[tokens]])\n",
    "\n",
    "def string_to_list(tokens):\n",
    "    return ast.literal_eval(tokens)\n",
    "\n",
    "def save_lda_model(ldaModule, location):\n",
    "    with open(location + \".pickle\", \"wb\") as output:\n",
    "        pickle.dump(ldaModule, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_lda_model(location):\n",
    "    with open(location + \".pickle\", \"rb\") as input_file:\n",
    "        ldaModule = pickle.load(input_file)\n",
    "    return ldaModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Module implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dictionary(doc_collection, use_collocations=True, doc_threshold=3):\n",
    "    if use_collocations:\n",
    "        doc_collection = get_word_collocations(doc_collection)\n",
    "    else:\n",
    "        doc_collection = [string_to_list(t) for t in doc_collection]\n",
    "\n",
    "    dictionary = corpora.Dictionary(doc_collection)\n",
    "\n",
    "    if doc_threshold > 0:\n",
    "        dictionary.filter_extremes(no_below = doc_threshold)\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "def build_corpus(doc_collection, dictionary):\n",
    "    corpus = [dictionary.doc2bow(list_of_tokens) for list_of_tokens in doc_collection]\n",
    "    return corpus\n",
    "\n",
    "def build_lda_model(corpus, dictionary, num_topics = 20, passes = 4, alpha = 0.01, eta = 0.01):\n",
    "    model = models.LdaModel(corpus,\n",
    "                            num_topics = num_topics,\n",
    "                            id2word = dictionary,\n",
    "                            passes = passes,\n",
    "                            alpha = [alpha] * num_topics,\n",
    "                            eta = [eta] * len(dictionary.keys()))\n",
    "    return model\n",
    "\n",
    "def get_topics(model, corpus, num_docs):\n",
    "    topics = [model[corpus[i]] for i in range(num_docs)]\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = build_dictionary(documents)\n",
    "corpus = build_corpus(documents, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(documents, corpus, dictionary, k, a, b, passes):\n",
    "    model = build_lda_model(corpus, \n",
    "                            dictionary, \n",
    "                            num_topics = k,\n",
    "                            passes = passes,\n",
    "                            alpha = a,\n",
    "                            eta = b)\n",
    "    coherence_model_lda = CoherenceModel(model = model, \n",
    "                                         texts = documents, \n",
    "                                         dictionary = dictionary, \n",
    "                                         coherence='c_v')\n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "topics_range = range(min_topics, max_topics)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = len(corpus)\n",
    "corpus_sets = [#ClippedCorpus(corpus, num_docs*0.25), \n",
    "               #ClippedCorpus(corpus, num_docs*0.5), \n",
    "               ClippedCorpus(corpus, int(num_docs*0.75)), \n",
    "               corpus]\n",
    "corpus_title = ['75% Corpus', '100% Corpus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Starting corpus set 0\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Starting corpus set 1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "# LDA model training passes\n",
    "passes = 5\n",
    "\n",
    "# iterate through validation corpuses\n",
    "for i in range(len(corpus_sets)):\n",
    "    # iterate through number of topics\n",
    "    print(\"~\"*30)\n",
    "    print(\"Starting corpus set {}\".format(i))\n",
    "    print(\"~\"*30)\n",
    "    for k in topics_range:\n",
    "        # iterate through alpha values\n",
    "        for a in alpha:\n",
    "            # iterare through beta values\n",
    "            for b in beta:\n",
    "                # get the coherence score for the given parameters\n",
    "                cv = compute_coherence_values(documents, \n",
    "                                              corpus = corpus_sets[i], \n",
    "                                              dictionary = dictionary, \n",
    "                                              k = k, a = a, b = b, passes = passes)\n",
    "                # Save the model results\n",
    "                model_results['Validation_Set'].append(corpus_title[i])\n",
    "                model_results['Topics'].append(k)\n",
    "                model_results['Alpha'].append(a)\n",
    "                model_results['Beta'].append(b)\n",
    "                model_results['Coherence'].append(cv)\n",
    "\n",
    "pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Validation_Set  Topics  Alpha  Beta  Coherence\n",
       "0     75% Corpus       2   0.01  0.01   0.622299\n",
       "1     75% Corpus       2   0.01  0.31   0.893531\n",
       "2     75% Corpus       2   0.01  0.61   0.631271\n",
       "3     75% Corpus       2   0.01  0.91   0.621133\n",
       "4     75% Corpus       2   0.31  0.01   0.619181"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Validation_Set</th>\n      <th>Topics</th>\n      <th>Alpha</th>\n      <th>Beta</th>\n      <th>Coherence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>75% Corpus</td>\n      <td>2</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.622299</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>75% Corpus</td>\n      <td>2</td>\n      <td>0.01</td>\n      <td>0.31</td>\n      <td>0.893531</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>75% Corpus</td>\n      <td>2</td>\n      <td>0.01</td>\n      <td>0.61</td>\n      <td>0.631271</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>75% Corpus</td>\n      <td>2</td>\n      <td>0.01</td>\n      <td>0.91</td>\n      <td>0.621133</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>75% Corpus</td>\n      <td>2</td>\n      <td>0.31</td>\n      <td>0.01</td>\n      <td>0.619181</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "res = pd.read_csv('lda_tuning_results.csv')\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res['Validation_Set'] = res['Validation_Set'].map(lambda x: 75 if x == \"75% Corpus\" else 100)\n",
    "res_75 = res[res['Validation_Set'] == \"75% Corpus\"]\n",
    "res_100 = res[res['Validation_Set'] == \"100% Corpus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Validation_Set  Topics  Alpha  Beta  Coherence\n",
       "192    100% Corpus       5   0.01  0.01   0.556172\n",
       "193    100% Corpus       5   0.01  0.31   0.466264\n",
       "194    100% Corpus       5   0.01  0.61   0.593936\n",
       "195    100% Corpus       5   0.01  0.91   0.474216\n",
       "196    100% Corpus       5   0.31  0.01   0.837624\n",
       "197    100% Corpus       5   0.31  0.31   0.582651\n",
       "198    100% Corpus       5   0.31  0.61   0.695920\n",
       "199    100% Corpus       5   0.31  0.91   0.597254\n",
       "200    100% Corpus       5   0.61  0.01   0.709315\n",
       "201    100% Corpus       5   0.61  0.31   0.698091\n",
       "202    100% Corpus       5   0.61  0.61   0.568622\n",
       "203    100% Corpus       5   0.61  0.91   0.673111\n",
       "204    100% Corpus       5   0.91  0.01   0.832939\n",
       "205    100% Corpus       5   0.91  0.31   0.807044\n",
       "206    100% Corpus       5   0.91  0.61   0.829822\n",
       "207    100% Corpus       5   0.91  0.91   0.734367"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Validation_Set</th>\n      <th>Topics</th>\n      <th>Alpha</th>\n      <th>Beta</th>\n      <th>Coherence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>192</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.01</td>\n      <td>0.01</td>\n      <td>0.556172</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.01</td>\n      <td>0.31</td>\n      <td>0.466264</td>\n    </tr>\n    <tr>\n      <th>194</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.01</td>\n      <td>0.61</td>\n      <td>0.593936</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.01</td>\n      <td>0.91</td>\n      <td>0.474216</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.31</td>\n      <td>0.01</td>\n      <td>0.837624</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.31</td>\n      <td>0.31</td>\n      <td>0.582651</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.31</td>\n      <td>0.61</td>\n      <td>0.695920</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.31</td>\n      <td>0.91</td>\n      <td>0.597254</td>\n    </tr>\n    <tr>\n      <th>200</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.61</td>\n      <td>0.01</td>\n      <td>0.709315</td>\n    </tr>\n    <tr>\n      <th>201</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.61</td>\n      <td>0.31</td>\n      <td>0.698091</td>\n    </tr>\n    <tr>\n      <th>202</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.61</td>\n      <td>0.61</td>\n      <td>0.568622</td>\n    </tr>\n    <tr>\n      <th>203</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.61</td>\n      <td>0.91</td>\n      <td>0.673111</td>\n    </tr>\n    <tr>\n      <th>204</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.91</td>\n      <td>0.01</td>\n      <td>0.832939</td>\n    </tr>\n    <tr>\n      <th>205</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.91</td>\n      <td>0.31</td>\n      <td>0.807044</td>\n    </tr>\n    <tr>\n      <th>206</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.91</td>\n      <td>0.61</td>\n      <td>0.829822</td>\n    </tr>\n    <tr>\n      <th>207</th>\n      <td>100% Corpus</td>\n      <td>5</td>\n      <td>0.91</td>\n      <td>0.91</td>\n      <td>0.734367</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "res_100[res_100['Topics'] == 5] \n",
    "# k = 4, a = 0.91, b = 0.91 -> 0.537146\n",
    "# k = 5, a = 0.31, b = 0.91 -> 0.521962"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Validation_Set  Topics  Alpha  Beta  Coherence\n",
       "238    100% Corpus       7   0.91  0.61   0.866113"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Validation_Set</th>\n      <th>Topics</th>\n      <th>Alpha</th>\n      <th>Beta</th>\n      <th>Coherence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>238</th>\n      <td>100% Corpus</td>\n      <td>7</td>\n      <td>0.91</td>\n      <td>0.61</td>\n      <td>0.866113</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "c = res_100['Coherence']\n",
    "info_max_c = res_100[res_100['Coherence'] == max(res_100['Coherence'])]\n",
    "info_max_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Coherence @1: 0.8201182761426324\n",
      "Coherence @10: 0.709113028816256\n",
      "Coherence @20: 0.5864714063151694\n",
      "Coherence @30: 0.5860337716911111\n",
      "Coherence @40: 0.5908862420556753\n",
      "Coherence @50: 0.7217586520605487\n",
      "Coherence @60: 0.6084338427911781\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 70, 10):\n",
    "    passes = i\n",
    "    if i == 0:\n",
    "        passes = 1\n",
    "    cv = compute_coherence_values(documents, \n",
    "                              corpus = corpus, \n",
    "                              dictionary = dictionary, \n",
    "                              k = 5, a = 0.31, b = 0.01, passes = passes)\n",
    "    print(\"Coherence @{}: {}\".format(passes, cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "passes = 10\n",
    "a = 0.31\n",
    "b = 0.01\n",
    "\n",
    "final_lda_model = build_lda_model(corpus, \n",
    "                            dictionary, \n",
    "                            num_topics = k,\n",
    "                            passes = passes,\n",
    "                            alpha = a,\n",
    "                            eta = b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.025*\"mens\" + 0.022*\"coronaviru\" + 0.017*\"virus\" + 0.010*\"zeggen\" + 0.009*\"aantal\" + 0.009*\"nieuw\" + 0.007*\"maken\" + 0.007*\"patiënt\" + 0.007*\"groot\" + 0.007*\"besmetting\"'),\n",
       " (1,\n",
       "  '0.084*\"jaar\" + 0.063*\"optreden\" + 0.042*\"gemeente\" + 0.042*\"overleg\" + 0.042*\"idee\" + 0.021*\"bekijken\" + 0.021*\"financieel\" + 0.021*\"tekst\" + 0.021*\"vieren\" + 0.021*\"verschillend\"'),\n",
       " (2,\n",
       "  '0.033*\"ziekte\" + 0.033*\"coronacrisi\" + 0.033*\"waarschuwen\" + 0.033*\"kijken\" + 0.033*\"schrijven\" + 0.033*\"verspreiden\" + 0.033*\"werken\" + 0.033*\"ontwikkelen\" + 0.033*\"reageren\" + 0.033*\"virus\"'),\n",
       " (3,\n",
       "  '0.182*\"vrijheid\" + 0.069*\"hierover\" + 0.057*\"jaar\" + 0.038*\"idee\" + 0.031*\"frans\" + 0.031*\"vertellen\" + 0.031*\"twee\" + 0.028*\"veiligheidsregio\" + 0.028*\"aanwezig\" + 0.028*\"gemeente\"'),\n",
       " (4,\n",
       "  '0.013*\"coronaviru\" + 0.010*\"houden\" + 0.010*\"maken\" + 0.009*\"china\" + 0.009*\"werknemer\" + 0.009*\"heel\" + 0.009*\"blijven\" + 0.008*\"bedrijf\" + 0.008*\"maatregel\" + 0.007*\"zien\"')]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "final_lda_model.show_topics(formatted=True, num_topics=k, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from core_modules.topic_extraction.lda_module import LdaModule\n",
    "import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "module = LdaModule(trained = False)\n",
    "module.lang = \"nl\"\n",
    "module.num_topics = k\n",
    "module.dictionary = dictionary\n",
    "module.corpus = corpus\n",
    "module.model = final_lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tuned_models/lda_model_nl.pickle\", \"wb\") as output:\n",
    "    pickle.dump(module, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.43128200248726706\n"
     ]
    }
   ],
   "source": [
    "final_cv = compute_coherence_values(documents, \n",
    "                              corpus = corpus, \n",
    "                              dictionary = dictionary, \n",
    "                              k = k, a = a, b = b, passes = k)\n",
    "print(final_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'import pyLDAvis.gensim\\nimport pickle\\nimport pyLDAvis\\n\\npyLDAvis.enable_notebook()\\nLDAvis_prepared = pyLDAvis.gensim.prepare(final_lda_model, corpus, dictionary)\\n\\nLDAvis_prepared'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "'''import pyLDAvis.gensim\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(final_lda_model, corpus, dictionary)\n",
    "\n",
    "LDAvis_prepared'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "dd32254f587d8a5ffd0187cda5a1807d3e2641e3d40bea739860f45ce231ba20"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}